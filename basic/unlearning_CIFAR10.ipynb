{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/basics-lab/unlearning-MIA/blob/master/basic/unlearning_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rg6hMnlC3tdi"
   },
   "source": [
    "<img src='https://unlearning-challenge.github.io/Unlearning-logo.png' width='100px'>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  * üíæ In the first section we'll load a sample dataset (CIFAR10) and pre-trained model (ResNet18).\n",
    "\n",
    "  * üéØ In the second section we'll develop the unlearning algorithm. We start by splitting the original training set into a retain set and a forget set. The goal of an unlearning algorithm is to update the pre-trained model so that it approximates as much as possible a model that has been trained on the retain set but not on the forget set. We provide a simple unlearning algorithm as a starting point for participants to develop their own unlearning algorithms.\n",
    "\n",
    "  * üèÖ In the third section we'll score our unlearning algorithm using a simple membership inference attacks (MIA). Note that this is a different evaluation than the one that will be used in the competition's submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "auNnrRF_pcDh",
    "outputId": "46df2ace-b2e3-49b6-f8c7-ff1bcd71c47a"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-0c86b0708d62>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    cd /unlearning-MIA/\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/basics-lab/unlearning-MIA.git\n",
    "!pip install opacus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25KMguUQsADi",
    "outputId": "eb573e12-cdd1-4310-b325-0dc311fa38ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/unlearning-MIA\n"
     ]
    }
   ],
   "source": [
    "cd /unlearning-MIA/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nived.rajaraman/Documents/GitHub/unlearning-MIA\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SLQO6KgLZF9a",
    "outputId": "d9c20e12-7b9c-4fde-add8-1e6107993048"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbasic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maugment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_signal_on_augmented_data\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbasic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     load_dataset_for_existing_models,\n\u001b[1;32m     19\u001b[0m     load_existing_models,\n\u001b[1;32m     20\u001b[0m     load_existing_target_model,\n\u001b[1;32m     21\u001b[0m     prepare_datasets,\n\u001b[1;32m     22\u001b[0m     prepare_datasets_for_reference_in_attack,\n\u001b[1;32m     23\u001b[0m     prepare_datasets_for_sample_privacy_risk,\n\u001b[1;32m     24\u001b[0m     prepare_information_source,\n\u001b[1;32m     25\u001b[0m     prepare_models,\n\u001b[1;32m     26\u001b[0m     prepare_priavcy_risk_report,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbasic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_dataset, get_dataset_subset\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbasic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_roc, plot_signal_histogram\n",
      "File \u001b[0;32m~/Documents/GitHub/unlearning-MIA/basic/core.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inference, train\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_split, load_models_by_conditions, load_models_by_model_idx\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprivacy_meter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audit_report\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprivacy_meter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetricEnum\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprivacy_meter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudit_report\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ROCCurveReport, SignalHistogramReport\n",
      "File \u001b[0;32m~/Documents/GitHub/unlearning-MIA/privacy_meter/audit_report.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msn\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interpolate\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "\"\"\"This file is the main entry point for running the privacy auditing.\"\"\"\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, model_selection\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from basic.augment import get_signal_on_augmented_data\n",
    "from basic.core import (\n",
    "    load_dataset_for_existing_models,\n",
    "    load_existing_models,\n",
    "    load_existing_target_model,\n",
    "    prepare_datasets,\n",
    "    prepare_datasets_for_reference_in_attack,\n",
    "    prepare_datasets_for_sample_privacy_risk,\n",
    "    prepare_information_source,\n",
    "    prepare_models,\n",
    "    prepare_priavcy_risk_report,\n",
    ")\n",
    "from basic.dataset import get_dataset, get_dataset_subset\n",
    "from basic.plot import plot_roc, plot_signal_histogram\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from torch import nn\n",
    "from basic.util import (\n",
    "    check_configs,\n",
    "    load_leave_one_out_models,\n",
    "    load_models_with_data_idx_list,\n",
    "    load_models_without_data_idx_list,\n",
    "    sweep,\n",
    ")\n",
    "\n",
    "from privacy_meter.audit import Audit\n",
    "from privacy_meter.model import PytorchModelTensor\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(\"Packages imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ppzg6RuranqP"
   },
   "source": [
    "# Create logger for current run\n",
    "\n",
    "In this section, we'll create a logger object for the current run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5LTqkzdaviT"
   },
   "outputs": [],
   "source": [
    "def setup_log(name: str, save_file: bool):\n",
    "    \"\"\"Generate the logger for the current run.\n",
    "    Args:\n",
    "        name (str): Logging file name.\n",
    "        save_file (bool): Flag about whether to save to file.\n",
    "    Returns:\n",
    "        logging.Logger: Logger object for the current run.\n",
    "    \"\"\"\n",
    "    my_logger = logging.getLogger(name)\n",
    "    my_logger.setLevel(logging.INFO)\n",
    "    if save_file:\n",
    "        log_format = logging.Formatter(\"%(asctime)s %(levelname)-8s %(message)s\")\n",
    "        filename = f\"log_{name}.log\"\n",
    "        log_handler = logging.FileHandler(filename, mode=\"w\")\n",
    "        log_handler.setLevel(logging.INFO)\n",
    "        log_handler.setFormatter(log_format)\n",
    "        my_logger.addHandler(log_handler)\n",
    "\n",
    "    return my_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOjN9SPLcdjH"
   },
   "source": [
    "# üíæ Download dataset and initialize models\n",
    "\n",
    "In this section, we'll load the dataset and initialize models. main() calls the MIA either through audit_model or audit_model_sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZ_f-DFGbSip"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--cf\",\n",
    "        type=str,\n",
    "        default=\"basic/config_models_reference_in_out.yaml\",\n",
    "        help=\"Yaml file which contains the configurations\",\n",
    "    )\n",
    "\n",
    "    # Load the parameters\n",
    "    args = parser.parse_args()\n",
    "    with open(args.cf, \"rb\") as f:\n",
    "        configs = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "    check_configs(configs)\n",
    "    # Set the random seed, log_dir and inference_game\n",
    "    torch.manual_seed(configs[\"run\"][\"random_seed\"])\n",
    "    np.random.seed(configs[\"run\"][\"random_seed\"])\n",
    "    random.seed(configs[\"run\"][\"random_seed\"])\n",
    "\n",
    "    log_dir = configs[\"run\"][\"log_dir\"]\n",
    "    inference_game_type = configs[\"audit\"][\"privacy_game\"].upper()\n",
    "\n",
    "    # Set up the logger\n",
    "    logger = setup_log(\"time_analysis\", configs[\"run\"][\"time_log\"])\n",
    "\n",
    "    # Create folders for saving the logs if they do not exist\n",
    "    Path(log_dir).mkdir(parents=True, exist_ok=True)\n",
    "    report_dir = f\"{log_dir}/{configs['audit']['report_log']}\"\n",
    "    Path(report_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Load or initialize models based on metadata\n",
    "    if os.path.exists((f\"{log_dir}/models_metadata.pkl\")):\n",
    "        with open(f\"{log_dir}/models_metadata.pkl\", \"rb\") as f:\n",
    "            model_metadata_list = pickle.load(f)\n",
    "    else:\n",
    "        model_metadata_list = {\"model_metadata\": {}, \"current_idx\": 0}\n",
    "    # Load the dataset\n",
    "    dataset = get_dataset(configs[\"data\"][\"dataset\"], configs[\"data\"][\"data_dir\"])\n",
    "\n",
    "    privacy_game = configs[\"audit\"][\"privacy_game\"]\n",
    "    attack = configs[\"audit\"][\"algorithm\"]\n",
    "\n",
    "    if privacy_game in [\"avg_privacy_loss_training_algo\", \"privacy_loss_model\"]:\n",
    "      audit_model(configs, privacy_game, dataset, model_metadata_list, logger)\n",
    "\n",
    "    else:\n",
    "      audit_model_rio(configs, privacy_game, dataset, model_metadata_list, logger)\n",
    "\n",
    "    ############################\n",
    "    # END\n",
    "    ############################\n",
    "    logger.info(\n",
    "        \"Run the privacy meter for the all steps costs %0.5f seconds\",\n",
    "        time.time() - start_time,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpjyZfZwd7of"
   },
   "source": [
    "# Privacy auditing for a model or an algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBLmTmfidAJC"
   },
   "outputs": [],
   "source": [
    "def audit_model(configs, privacy_game, dataset, model_metadata_list, logger):\n",
    "  if \"reference_in_out\" not in configs['audit']['algorithm']:\n",
    "    raise ValueError(\"Currently only reference_in_out is implemented. configs['audit']['algorithm'] must contain 'reference_in_out'\")\n",
    "        # Start time of audit\n",
    "        baseline_time = time.time()\n",
    "\n",
    "        # Load the trained models from disk\n",
    "        if model_metadata_list[\"current_idx\"] > 0:\n",
    "            target_model_idx_list = load_existing_target_model(\n",
    "                len(dataset), model_metadata_list, configs\n",
    "            )\n",
    "            trained_target_dataset_list = load_dataset_for_existing_models(\n",
    "                len(dataset),\n",
    "                model_metadata_list,\n",
    "                target_model_idx_list,\n",
    "                configs[\"data\"],\n",
    "            )\n",
    "\n",
    "            trained_target_models_list = load_existing_models(\n",
    "                model_metadata_list,\n",
    "                target_model_idx_list,\n",
    "                configs[\"train\"][\"model_name\"],\n",
    "                dataset,\n",
    "                configs[\"data\"][\"dataset\"],\n",
    "            )\n",
    "            num_target_models = configs[\"train\"][\"num_target_model\"] - len(\n",
    "                trained_target_dataset_list\n",
    "            )\n",
    "        else:\n",
    "            target_model_idx_list = []\n",
    "            trained_target_models_list = []\n",
    "            trained_target_dataset_list = []\n",
    "            num_target_models = configs[\"train\"][\"num_target_model\"]\n",
    "\n",
    "        # Prepare the datasets\n",
    "        print(25 * \">\" + \"Prepare the the datasets\")\n",
    "        data_split_info = prepare_datasets(\n",
    "            len(dataset), num_target_models, configs[\"data\"]\n",
    "        )\n",
    "\n",
    "        logger.info(\n",
    "            \"Prepare the datasets costs %0.5f seconds\", time.time() - baseline_time\n",
    "        )\n",
    "\n",
    "        # Prepare the target models\n",
    "        print(25 * \">\" + \"Prepare the the target models\")\n",
    "        baseline_time = time.time()\n",
    "\n",
    "        new_model_list, model_metadata_list, new_target_model_idx_list = prepare_models(\n",
    "            log_dir,\n",
    "            dataset,\n",
    "            data_split_info,\n",
    "            configs[\"train\"],\n",
    "            model_metadata_list,\n",
    "            configs[\"data\"][\"dataset\"],\n",
    "        )\n",
    "\n",
    "        # Combine the trained models with the existing models\n",
    "        model_list = [*new_model_list, *trained_target_models_list]\n",
    "        data_split_info[\"split\"] = [\n",
    "            *data_split_info[\"split\"],\n",
    "            *trained_target_dataset_list,\n",
    "        ]\n",
    "        target_model_idx_list = [*new_target_model_idx_list, *target_model_idx_list]\n",
    "\n",
    "        logger.info(\n",
    "            \"Prepare the target model costs %0.5f seconds\", time.time() - baseline_time\n",
    "        )\n",
    "\n",
    "        # Prepare the information sources\n",
    "        print(25 * \">\" + \"Prepare the information source, including attack models\")\n",
    "        baseline_time = time.time()\n",
    "        (\n",
    "            target_info_source,\n",
    "            reference_info_source,\n",
    "            metrics,\n",
    "            log_dir_list,\n",
    "            model_metadata_list,\n",
    "        ) = prepare_information_source(\n",
    "            log_dir,\n",
    "            dataset,\n",
    "            data_split_info,\n",
    "            model_list,\n",
    "            configs[\"audit\"],\n",
    "            model_metadata_list,\n",
    "            target_model_idx_list,\n",
    "            configs[\"train\"][\"model_name\"],\n",
    "            configs[\"data\"][\"dataset\"],\n",
    "        )\n",
    "        logger.info(\n",
    "            \"Prepare the information source costs %0.5f seconds\",\n",
    "            time.time() - baseline_time,\n",
    "        )\n",
    "\n",
    "        # Call core of Privacy Meter\n",
    "        print(25 * \">\" + \"Auditing the privacy risk\")\n",
    "        baseline_time = time.time()\n",
    "        audit_obj = Audit(\n",
    "            metrics=metrics,\n",
    "            inference_game_type=inference_game_type,\n",
    "            target_info_sources=target_info_source,\n",
    "            reference_info_sources=reference_info_source,\n",
    "            fpr_tolerances=None,\n",
    "            logs_directory_names=log_dir_list,\n",
    "        )\n",
    "        audit_obj.prepare()\n",
    "        audit_results = audit_obj.run()\n",
    "        logger.info(\n",
    "            \"Prepare the Privacy Meter result costs %0.5f seconds\",\n",
    "            time.time() - baseline_time,\n",
    "        )\n",
    "\n",
    "        # Generate the privacy risk report\n",
    "        print(25 * \">\" + \"Generating privacy risk report\")\n",
    "        baseline_time = time.time()\n",
    "        prepare_priavcy_risk_report(\n",
    "            log_dir,\n",
    "            audit_results,\n",
    "            configs[\"audit\"],\n",
    "            save_path=f\"{log_dir}/{configs['audit']['report_log']}\",\n",
    "        )\n",
    "        print(100 * \"#\")\n",
    "\n",
    "        logger.info(\n",
    "            \"Prepare the plot for the privacy risk report costs %0.5f seconds\",\n",
    "            time.time() - baseline_time,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zDb2jMbeKMR"
   },
   "source": [
    "# Privacy Auditing for a model with reference_in_out attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOub_XsleKko"
   },
   "outputs": [],
   "source": [
    "def audit_model_rio(configs, privacy_game, dataset, model_metadata_list, logger)\n",
    "    if \"reference_in_out\" not in configs[\"audit\"][\"algorithm\"]:\n",
    "      ValueError(\"reference_in_out should be present in configs['audit']['algorithm']\")\n",
    "        # The following code of generating the data is modified from the original code in the repo: https://github.com/tensorflow/privacy/tree/master/research/mi_lira_2021\n",
    "        baseline_time = time.time()\n",
    "        p_ratio = configs[\"data\"][\"keep_ratio\"]\n",
    "        dataset_size = configs[\"data\"][\"dataset_size\"]\n",
    "        number_of_models_total = (\n",
    "            configs[\"audit\"][\"num_in_models\"]\n",
    "            + configs[\"audit\"][\"num_out_models\"]\n",
    "            + configs[\"train\"][\"num_target_model\"]\n",
    "        )\n",
    "        (\n",
    "            data_split_info,\n",
    "            keep_matrix,\n",
    "            target_data_index,\n",
    "        ) = prepare_datasets_for_reference_in_attack(\n",
    "            len(dataset),\n",
    "            dataset_size,\n",
    "            num_models=(number_of_models_total),\n",
    "            keep_ratio=p_ratio,\n",
    "            is_uniform=False,\n",
    "        )\n",
    "        data, targets = get_dataset_subset(\n",
    "            dataset,\n",
    "            target_data_index,\n",
    "            configs[\"train\"][\"model_name\"],\n",
    "            device=configs[\"train\"][\"device\"],\n",
    "        )  # only the train dataset we want to attack\n",
    "        logger.info(\n",
    "            \"Preparing the datasets costs %0.5f seconds\",\n",
    "            time.time() - baseline_time,\n",
    "        )\n",
    "        baseline_time = time.time()\n",
    "        if model_metadata_list[\"current_idx\"] == 0:\n",
    "            # if the models are already trained and saved in the disk\n",
    "            (model_list, model_metadata_dict, trained_model_idx_list) = prepare_models(\n",
    "                log_dir,\n",
    "                dataset,\n",
    "                data_split_info,\n",
    "                configs[\"train\"],\n",
    "                model_metadata_list,\n",
    "                configs[\"data\"][\"dataset\"],\n",
    "            )\n",
    "            logger.info(\n",
    "                \"Preparing the models costs %0.5f seconds\",\n",
    "                time.time() - baseline_time,\n",
    "            )\n",
    "            baseline_time = time.time()\n",
    "            signals = []\n",
    "            for model in model_list:\n",
    "                model_pm = PytorchModelTensor(\n",
    "                    model_obj=model,\n",
    "                    loss_fn=nn.CrossEntropyLoss(),\n",
    "                    device=configs[\"audit\"][\"device\"],\n",
    "                    batch_size=configs[\"audit\"][\"audit_batch_size\"],\n",
    "                )\n",
    "                signals.append(\n",
    "                    get_signal_on_augmented_data(\n",
    "                        model_pm,\n",
    "                        data,\n",
    "                        targets,\n",
    "                        method=configs[\"audit\"][\"augmentation\"],\n",
    "                        signal=configs[\"audit\"][\"signal\"],\n",
    "                    )\n",
    "                )\n",
    "            logger.info(\n",
    "                \"Preparing the signals costs %0.5f seconds\",\n",
    "                time.time() - baseline_time,\n",
    "            )\n",
    "        else:\n",
    "            baseline_time = time.time()\n",
    "            signals = []\n",
    "            for idx in range(model_metadata_list[\"current_idx\"]):\n",
    "                print(\"Load the model and compute signals for model %d\" % idx)\n",
    "                model_pm = PytorchModelTensor(\n",
    "                    model_obj=load_existing_models(\n",
    "                        model_metadata_list,\n",
    "                        [idx],\n",
    "                        configs[\"train\"][\"model_name\"],\n",
    "                        dataset,\n",
    "                        configs[\"data\"][\"dataset\"],\n",
    "                    )[0],\n",
    "                    loss_fn=nn.CrossEntropyLoss(),\n",
    "                    device=configs[\"audit\"][\"device\"],\n",
    "                    batch_size=10000,\n",
    "                )\n",
    "                signals.append(\n",
    "                    get_signal_on_augmented_data(\n",
    "                        model_pm,\n",
    "                        data,\n",
    "                        targets,\n",
    "                        method=configs[\"audit\"][\"augmentation\"],\n",
    "                        signal=configs[\"audit\"][\"signal\"],\n",
    "                    )\n",
    "                )\n",
    "            logger.info(\n",
    "                \"Preparing the signals costs %0.5f seconds\",\n",
    "                time.time() - baseline_time,\n",
    "            )\n",
    "        baseline_time = time.time()\n",
    "        signals = np.array(signals)\n",
    "\n",
    "        # number of models we want to consider as test\n",
    "        num_target = configs[\"train\"][\"num_target_model\"]\n",
    "        target_signal = signals[:num_target, :]\n",
    "        reference_signals = signals[num_target:, :]\n",
    "        reference_keep_matrix = keep_matrix[num_target:, :]\n",
    "        membership = keep_matrix[:num_target, :]\n",
    "        in_signals = []\n",
    "        out_signals = []\n",
    "\n",
    "        for data_idx in range(dataset_size):\n",
    "            in_signals.append(\n",
    "                reference_signals[reference_keep_matrix[:, data_idx], data_idx]\n",
    "            )\n",
    "            out_signals.append(\n",
    "                reference_signals[~reference_keep_matrix[:, data_idx], data_idx]\n",
    "            )\n",
    "\n",
    "        in_size = min(min(map(len, in_signals)), configs[\"audit\"][\"num_in_models\"])\n",
    "        out_size = min(min(map(len, out_signals)), configs[\"audit\"][\"num_out_models\"])\n",
    "        in_signals = np.array([x[:in_size] for x in in_signals]).astype(\"float32\")\n",
    "        out_signals = np.array([x[:out_size] for x in out_signals]).astype(\"float32\")\n",
    "        mean_in = np.median(in_signals, 1)\n",
    "        mean_out = np.median(out_signals, 1)\n",
    "        fix_variance = configs[\"audit\"][\"fix_variance\"]\n",
    "        if fix_variance:\n",
    "            std_in = np.std(in_signals)\n",
    "            std_out = np.std(in_signals)\n",
    "        else:\n",
    "            std_in = np.std(in_signals, 1)\n",
    "            std_out = np.std(out_signals, 1)\n",
    "\n",
    "        prediction = []\n",
    "        answers = []\n",
    "        for ans, sc in zip(membership, target_signal):\n",
    "            pr_in = -norm.logpdf(sc, mean_in, std_in + 1e-30)\n",
    "            pr_out = -norm.logpdf(sc, mean_out, std_out + 1e-30)\n",
    "            score = pr_in - pr_out\n",
    "            if len(score.shape) == 2:  # the score is of size (data_size, num_augments)\n",
    "                prediction.extend(score.mean(1))\n",
    "                fpr_list, tpr_list, _ = roc_curve(ans, -score.mean(1))\n",
    "            else:\n",
    "                prediction.extend(score)\n",
    "                fpr_list, tpr_list, _ = roc_curve(ans, -score)\n",
    "            answers.extend(ans)\n",
    "            acc = np.max(1 - (fpr_list + (1 - tpr_list)) / 2)\n",
    "            roc_auc = auc(fpr_list, tpr_list)\n",
    "\n",
    "        prediction = np.array(prediction)\n",
    "        answers = np.array(answers, dtype=bool)\n",
    "        fpr_list, tpr_list, _ = roc_curve(answers.ravel(), -prediction.ravel())\n",
    "        acc = np.max(1 - (fpr_list + (1 - tpr_list)) / 2)\n",
    "        roc_auc = auc(fpr_list, tpr_list)\n",
    "        logger.info(\n",
    "            \"Preparing the privacy risks results costs %0.5f seconds\",\n",
    "            time.time() - baseline_time,\n",
    "        )\n",
    "        low = tpr_list[np.where(fpr_list < 0.001)[0][-1]]\n",
    "        print(\"AUC %.4f, Accuracy %.4f, TPR@0.1%%FPR of %.4f\" % (roc_auc, acc, low))\n",
    "        plot_roc(\n",
    "            fpr_list,\n",
    "            tpr_list,\n",
    "            roc_auc,\n",
    "            f\"{log_dir}/{configs['audit']['report_log']}/ROC.png\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CYTGGV56EEMN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
